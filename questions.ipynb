{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanskrirtisingh/opt/anaconda3/envs/data_project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from depends.transform import generate_pdf_hi_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = generate_pdf_hi_res(filename=\"data/qwen2audio.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depends.question_gen import generate_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = generate_questions(elements=elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the main contribution of the audio language model \"Flamingo\"?', 'How does the Flamingo model differ from other existing audio language models?', 'Which LLM was introduced in 2023 and has a technical report published by OpenAI?', 'What is the primary focus of the GPT-4O model, as described in the OpenAI report?', 'What is Covost 2, and what is its significance in the field of speech-to-text translation?', 'How does Blsp (Bootstrapping Language-Speech Pre-training via Behavior Alignment) contribute to the development of LLMs for speech recognition?', 'What is the main goal of the MELD dataset, and how does it relate to multimodal understanding in conversations?', 'How do Gemini 1.5 models enable multimodal understanding across millions of tokens of context?', 'What is Robust Speech Recognition via Large-scale Weak Supervision, as described by Alec Radford et al. (2023)?', 'How does this approach contribute to the development of more robust speech recognition systems?', 'What is Direct Preference Optimization, and how do Rafael Rafailov et al. (2024) apply it to LLMs?', 'How do these models secretly function as reward models, according to the authors?', 'What is the main contribution of the SLM model in bridging the gap between speech and text foundation models?', \"How does Next-GPT's multimodal LLM architecture differ from other existing approaches?\"]\n"
     ]
    }
   ],
   "source": [
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
